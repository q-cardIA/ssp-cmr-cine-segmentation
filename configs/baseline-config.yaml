data:
  dimensionality: 2D # 2D/ #not implemented: 2D+T, 3D, 3D+T, 4D
  target_pixdim:
  - 1.25
  - 1.25
  target_size:
  - 256
  - 256
  image_grid_sample_mode: bicubic
  label_grid_sample_mode: nearest
  translate_to_center: True

  nr_sample_copies: 0 # number of copies of the same image with different augmentations

  to_one_hot:
    active: True
    nr_classes: 4

  augmentation:
    translation:
      prob: 1.0
      range:
      - -40.0
      - 40.0
    
    rotation:
      prob: 1.0
      range:
      - -180.0
      - 180.0
    
    scale:
      prob: 1.0
      range:
      - 0.7
      - 1.4
      linked: True
      
    flip_prob:
    - 0.5
    - 0.5
    
    gaussian_noise:
      prob: 0.2
      mean: 0.0
      std: 0.2
    
    gaussian_smooth:
      prob: 0.2
      sigma_x:
      - 0.5
      - 1.5
      sigma_y:
      - 0.5
      - 1.5
    
    scale_intensity:
      prob: 1.0
      factors:
      - 0.6
      - 1.5
    
    shift_intensity:
      prob: 1.0
      offsets:
      - -0.4
      - 0.4
    
    adjust_contrast:
      prob: 1.0
      gamma:
      - 0.7
      - 1.5

  intensity:
    normalization_mode: standardize # standardize/normalize
    reference_level: subject # subject/slice/current
    normalize:      
      target_min: -1.0
      target_max: 1.0
      source_min: None
      source_max: None
    clamp:
      active: False
      min_intensity: None
      max_intensity: None


dataset:
  split_file: default-cine-split.yaml
  subsets:
  - mm1       # possible keys: sa_cine/sa_cine_gt
  - mm2       # possible keys: sa_cine/sa_cine_gt (la_cine/la_cine_gt)
  key_pairs:
  - [sa_cine, sa_cine_gt]
  # key pairs indicate file names and output dict keys, applied to all used datasets:
  # - [sa_cine, sa_cine_gt]         # images and labels
  # - [sa_cine, none]               # only images
  # - [none, sa_cine_gt]            # only labels 
  meta_only_labels: False # only use label keys for meta data
  special_mode: None # ed_only, es_only # allows for only using ED or ES timeframes
  valid_partition: 0.2
  valid_split_seed: 0
  train_weighted_sampling_columns: None


dataloader:
  train:
    batch_size: 32
    drop_last: True
    shuffle: True
    augmentation: True
  valid:
    batch_size: 128
    drop_last: False
    shuffle: False
    augmentation: False


unet:
  nr_image_channels: 1
  channels_list:
  - 32
  - 64
  - 128
  - 256
  - 512
  - 512
  - 512
  nr_output_classes: 4
  nr_output_scales: -1
  weights_path: None # provide path to weights file for model finetuning


loss:
  cross_entropy_loss_weight: 0.5
  dice_loss_weight: 0.5
  dice_classes_weights:
  - 0.0
  - 1.0
  - 1.0
  - 1.0

metrics:
  dice_class_idxs:
  - 1
  - 2
  - 3

optimizer:  
  learning_rate: 0.01 # lower learning rate to 0.005 for finetuning
  momentum: 0.99
  nesterov: True
  weight_decay: 0.00003

training:
  nr_epochs_frozen_encoder: 0
  lr_scheduler_type: poly
  max_nr_epochs: 1000
  polynomial_scheduler_power: 0.9
  early_stopping:
    active: False
    patience: 4
    min_delta: 0.001


experiment:
  project: baseline_cine_segmentation
  name: baseline
  type: train # train/test
  seed: 0


general:
  num_workers: 4
  persistent_workers: True
  verbosity: 1
  
paths:
  data: "/home/bme001/shared/qcardia/data"
  